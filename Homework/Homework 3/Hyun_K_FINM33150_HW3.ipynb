{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<left>FINM 33160 - Machine Learning In Finance</left>\n",
    "<left>Winter 2023</left>\n",
    "<br>\n",
    "<h1><center> Homework 3 </center></h1>\n",
    "<center> Due - 23:59 [CST] February 29th, 2023</center>\n",
    "<br>\n",
    "<h3>Ki Hyun</h3>\n",
    "<h3>Student ID: 12125881</h3>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Imports </h3>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('use_inf_as_na', True)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "optuna.logging.set_verbosity(optuna.logging.FATAL)\n",
    "from functools import partial\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Constants </h3>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "home_dir = r'C:\\Users\\kwhyu\\OneDrive - The University of Chicago\\2023-1 Winter\\FINM 33160\\FINM-33160-W23'\n",
    "raw_data_dir = r'dataset.pkl'\n",
    "shap_features_dir = [r'Lecture 7\\shap_features_ada.pkl',\n",
    "                 r'Lecture 7\\shap_features_ada_01.pkl',\n",
    "                 r'Lecture 7\\shap_features_ada_02.pkl']\n",
    "training_dates = {'start': '2001-01-01', 'end': '2004-01-01'}\n",
    "validation_dates = {'start': '2004-01-01', 'end': '2004-04-01'}\n",
    "testing_dates = {'start': '2003-01-01', 'end': '2018-01-01'}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Helper-Functions </h3>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def f(x):\n",
    "\n",
    "    if x > 0.01:\n",
    "        return 1\n",
    "    elif x < -0.025:\n",
    "\n",
    "        return -1\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        return 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def max_drawdown(returns):\n",
    "        local_max = [n for n in range(len(returns)-1) if ((n==0) and (returns[0] > returns[1])) or\n",
    "           ((n > 0) and  (returns[n-1]<returns[n]) and (returns[n+1]<returns[n]))]\n",
    "\n",
    "        local_min = [n for n in range(1,len(returns)) if ((n == len(returns)-1) and (returns[-1] < returns[-2])) or\n",
    "                (returns[n-1]>returns[n]) and (returns[n+1]>returns[n])]\n",
    "\n",
    "        def next_local_min(n):\n",
    "            if [m for m in local_min if m > n]:\n",
    "                return [m for m in local_min if m > n][0]\n",
    "            else: return None\n",
    "\n",
    "        drawdowns = [(n,next_local_min(n)) for n in local_max]\n",
    "        drawdown_values = [returns[n] - returns[m] for (n,m) in drawdowns if m != None]\n",
    "        if drawdown_values:\n",
    "            return  np.max(drawdown_values)\n",
    "        else: return 0.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def accuracy_objective(trial:Trial,train=None,labels=None,val=None,val_labels=None):\n",
    "\n",
    "    ada_m_depth = trial.suggest_int('max_depth',1,5)\n",
    "    ada_n_estimators = trial.suggest_int('n_estimators', 10,100,step=10)\n",
    "    ada_learning_rate = trial.suggest_float('learning_rate',0.1,0.5, step=0.1)\n",
    "\n",
    "\n",
    "    ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=ada_m_depth),\n",
    "                                 n_estimators=ada_n_estimators,\n",
    "                                 learning_rate=ada_learning_rate,\n",
    "                                 algorithm=\"SAMME.R\")\n",
    "\n",
    "    ada_clf.fit(train,labels)\n",
    "    accuracy = ada_clf.score(val,val_labels)\n",
    "\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def mdd_objective(trial:Trial,train=None,labels=None,val=None,val_rets=None):\n",
    "\n",
    "    ada_m_depth = trial.suggest_int('max_depth',1,5)\n",
    "    ada_n_estimators = trial.suggest_int('n_estimators', 10,100,step=10)\n",
    "    ada_learning_rate = trial.suggest_float('learning_rate',0.1,0.5, step=0.1)\n",
    "\n",
    "\n",
    "    ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=ada_m_depth),\n",
    "                                 n_estimators=ada_n_estimators,\n",
    "                                 learning_rate=ada_learning_rate,\n",
    "                                 algorithm=\"SAMME.R\")\n",
    "    ada_clf.fit(train,labels)\n",
    "    pred = ada_clf.predict(val)\n",
    "    profit = (pred * val_rets).sum()\n",
    "    position = np.sum(np.abs(pred))\n",
    "    x = (1/position) * profit\n",
    "\n",
    "    return -x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Data </h3>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "raw_data = pd.read_pickle(os.path.join(home_dir, raw_data_dir))\n",
    "\n",
    "data = raw_data[raw_data['market_cap'] > 1000.0]\n",
    "data = data.copy()\n",
    "data.fillna(0.0,inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "data['rel_performance'] = data['pred_rel_return'].apply(f)\n",
    "data.reset_index(inplace=True,)\n",
    "data.set_index('date',inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "df_train = data.loc[training_dates.get('start'):training_dates.get('end')]\n",
    "df_valid = data.loc[validation_dates.get('start'):validation_dates.get('end')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "train = df_train.reset_index().drop(['ticker','date',\n",
    "                                     'next_period_return',\n",
    "                                     'spy_next_period_return',\n",
    "                                     'rel_performance','pred_rel_return',\n",
    "                                     'return', 'cum_ret', 'spy_cum_ret'],axis=1)\n",
    "\n",
    "valid = df_valid.reset_index().drop(['ticker','date',\n",
    "                                    'next_period_return',\n",
    "                                   'spy_next_period_return',\n",
    "                                   'rel_performance','pred_rel_return',\n",
    "                                  'return', 'cum_ret', 'spy_cum_ret'],axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "valid_stock_returns = df_valid['next_period_return']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "y_train = df_train['rel_performance'].values\n",
    "y_valid = df_valid['rel_performance'].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "optimal_features_collection = []\n",
    "for features_dir in shap_features_dir:\n",
    "    with open(os.path.join(home_dir, features_dir), 'rb') as f:\n",
    "        optimal_features_collection.append(pickle.load(f))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "windows = len(optimal_features_collection[0])\n",
    "start_dates = [pd.to_datetime(testing_dates.get('start')) + pd.DateOffset(months = 3 * i) for i in range(windows)]\n",
    "end_dates = [d + pd.DateOffset(months = 36) for d in start_dates]\n",
    "\n",
    "training_frames = [data.loc[d:d+pd.DateOffset(months = 36)] for d in start_dates]\n",
    "test_frames = [data.loc[d + pd.DateOffset(months=6):d+pd.DateOffset(months = 9)] for d in end_dates]\n",
    "\n",
    "training_data = [d.reset_index().drop\n",
    "                                 (['ticker','date',\n",
    "                                   'next_period_return',\n",
    "                                   'spy_next_period_return',\n",
    "                                   'rel_performance','pred_rel_return',\n",
    "                                  'return', 'cum_ret', 'spy_cum_ret'],axis=1) for d in training_frames]\n",
    "\n",
    "test_data = [d.reset_index().drop(['ticker','date',\n",
    "                                   'next_period_return',\n",
    "                                   'spy_next_period_return',\n",
    "                                   'rel_performance','pred_rel_return',\n",
    "                                  'return', 'cum_ret', 'spy_cum_ret'],axis=1) for d in test_frames]\n",
    "\n",
    "training_labels = [d['rel_performance'].values for d in training_frames]\n",
    "test_labels = [d['rel_performance'].values for d in test_frames]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Q1 </h2>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Optimizing by Accuracy </h3>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "study_accuracy = optuna.create_study(direction=\"maximize\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 21min 37s\n",
      "Wall time: 4min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "study_accuracy.optimize(partial(accuracy_objective, train=train, labels=y_train, val=valid, val_labels=y_valid),\n",
    "                        n_trials=20,n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "{'max_depth': 4, 'n_estimators': 20, 'learning_rate': 0.4}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_accuracy.best_params"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "accuracy_best_params = study_accuracy.best_params\n",
    "max_depth = accuracy_best_params.get('max_depth')\n",
    "del accuracy_best_params['max_depth']\n",
    "ada_clf_1 = AdaBoostClassifier(DecisionTreeClassifier(max_depth=max_depth),**accuracy_best_params)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 60)) while a minimum of 1 is required by AdaBoostClassifier.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[1;32m<timed exec>:6\u001B[0m\n",
      "File \u001B[1;32m~\\.virtualenvs\\FINM-33160-W23-zys-Qvij\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:700\u001B[0m, in \u001B[0;36mAdaBoostClassifier.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    683\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m    684\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Predict classes for X.\u001B[39;00m\n\u001B[0;32m    685\u001B[0m \n\u001B[0;32m    686\u001B[0m \u001B[38;5;124;03m    The predicted class of an input sample is computed as the weighted mean\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;124;03m        The predicted classes.\u001B[39;00m\n\u001B[0;32m    699\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 700\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecision_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m    703\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_\u001B[38;5;241m.\u001B[39mtake(pred \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\.virtualenvs\\FINM-33160-W23-zys-Qvij\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:761\u001B[0m, in \u001B[0;36mAdaBoostClassifier.decision_function\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    742\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute the decision function of ``X``.\u001B[39;00m\n\u001B[0;32m    743\u001B[0m \n\u001B[0;32m    744\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    758\u001B[0m \u001B[38;5;124;03m    class in ``classes_``, respectively.\u001B[39;00m\n\u001B[0;32m    759\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    760\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m--> 761\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_X\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    763\u001B[0m n_classes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_\n\u001B[0;32m    764\u001B[0m classes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_[:, np\u001B[38;5;241m.\u001B[39mnewaxis]\n",
      "File \u001B[1;32m~\\.virtualenvs\\FINM-33160-W23-zys-Qvij\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:94\u001B[0m, in \u001B[0;36mBaseWeightBoosting._check_X\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_X\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m     93\u001B[0m     \u001B[38;5;66;03m# Only called to validate X in non-fit methods, therefore reset=False\u001B[39;00m\n\u001B[1;32m---> 94\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     95\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     96\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     97\u001B[0m \u001B[43m        \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     98\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     99\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    100\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    101\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\FINM-33160-W23-zys-Qvij\\Lib\\site-packages\\sklearn\\base.py:546\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    544\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValidation should be done on X, y or both.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    545\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[1;32m--> 546\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    547\u001B[0m     out \u001B[38;5;241m=\u001B[39m X\n\u001B[0;32m    548\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n",
      "File \u001B[1;32m~\\.virtualenvs\\FINM-33160-W23-zys-Qvij\\Lib\\site-packages\\sklearn\\utils\\validation.py:931\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    929\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n\u001B[0;32m    930\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_samples \u001B[38;5;241m<\u001B[39m ensure_min_samples:\n\u001B[1;32m--> 931\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    932\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m sample(s) (shape=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m) while a\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    933\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m minimum of \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m is required\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    934\u001B[0m             \u001B[38;5;241m%\u001B[39m (n_samples, array\u001B[38;5;241m.\u001B[39mshape, ensure_min_samples, context)\n\u001B[0;32m    935\u001B[0m         )\n\u001B[0;32m    937\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_features \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m array\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m    938\u001B[0m     n_features \u001B[38;5;241m=\u001B[39m array\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[1;31mValueError\u001B[0m: Found array with 0 sample(s) (shape=(0, 60)) while a minimum of 1 is required by AdaBoostClassifier."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_data = []\n",
    "for optimal_features in optimal_features_collection:\n",
    "    x = [1]\n",
    "    for i in range(len(optimal_features)-2):\n",
    "            ada_clf_1.fit(training_data[i][optimal_features[i].values],training_labels[i])\n",
    "            pred_i = ada_clf_1.predict(test_data[i][optimal_features[i].values])\n",
    "\n",
    "            profit_i = (pred_i * test_frames[i]['next_period_return']).sum()\n",
    "            positions = np.sum(np.abs(pred_i))\n",
    "            x.append(x[i] + (x[i]/positions) * profit_i)\n",
    "    total_data.append(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(total_data):\n\u001B[0;32m      2\u001B[0m     x \u001B[38;5;241m=\u001B[39m total_data[i]\n\u001B[0;32m      3\u001B[0m     Sharpe \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mmean()\u001B[38;5;241m/\u001B[39mx\u001B[38;5;241m.\u001B[39mstd()\n",
      "\u001B[1;31mTypeError\u001B[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in range(len(total_data)):\n",
    "    x = total_data[i]\n",
    "    Sharpe = x.mean()/x.std()\n",
    "    MDD = max_drawdown(x)\n",
    "    print(\">>> Accuracy Maximization Objective, Optimal Features Set\", i+1, \"Strategy:\")\n",
    "    print(\"    Sharpe Ratio:\", Sharpe)\n",
    "    print(\"    Maximum Draw Down:\", MDD)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Optimizing by Max Drawdown </h3>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "study_mdd = optuna.create_study(direction=\"minimize\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "study_mdd.optimize(partial(mdd_objective, train=train, labels=y_train, val=valid, val_rets=valid_stock_returns),\n",
    "                   n_trials=20,n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "study_mdd.best_params"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mdd_best_params = study_mdd.best_params\n",
    "max_depth = mdd_best_params.get('max_depth')\n",
    "del mdd_best_params['max_depth']\n",
    "ada_clf_2 = AdaBoostClassifier(DecisionTreeClassifier(max_depth=max_depth),**mdd_best_params)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "total_data = []\n",
    "for optimal_features in optimal_features_collection:\n",
    "    x = [1]\n",
    "\n",
    "    for i in range(len(optimal_features)-2):\n",
    "\n",
    "            ada_clf_2.fit(training_data[i][optimal_features[i].values],training_labels[i])\n",
    "            pred_i = ada_clf_2.predict(test_data[i][optimal_features[i].values])\n",
    "\n",
    "            profit_i = (pred_i * test_frames[i]['next_period_return']).sum()\n",
    "            positions = np.sum(np.abs(pred_i))\n",
    "            x.append(x[i] + (x[i]/positions) * profit_i)\n",
    "    total_data.append(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in len(total_data):\n",
    "    x = total_data[i]\n",
    "    Sharpe = x.mean()/x.std()\n",
    "    MDD = max_drawdown(x)\n",
    "    print(\">>> Max Drawdown Minimization Objective, Optimal Features Set\", i+1, \"Strategy:\")\n",
    "    print(\"    Sharpe Ratio:\", Sharpe)\n",
    "    print(\"    Maximum Draw Down:\", MDD)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best strategy appears to be a combination of Max Drawdown Minimization Objective ('max_depth' = 5, 'n_estimators' =\n",
    "10, 'learning_rate = 0.5) and the 2nd set in the optimal features provided."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
