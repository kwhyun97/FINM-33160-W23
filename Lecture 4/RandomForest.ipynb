{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn import tree\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib import cm\n",
    "import umap\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A data set with 4 features and 4 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=500,n_features=4, n_redundant=0, n_informative=2,\n",
    "                             n_clusters_per_class=1, n_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'umap' has no attribute 'UMAP'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m reducer \u001B[38;5;241m=\u001B[39m \u001B[43mumap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mUMAP\u001B[49m()\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'umap' has no attribute 'UMAP'"
     ]
    }
   ],
   "source": [
    "reducer = umap.UMAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = reducer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_embedded[:,0],X_embedded[:,1],c=y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data = X, columns = [0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "C = Counter(y)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.most_common()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = { k:v/total for (k,v) in C.items()}\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_index = np.sum([ p * (1 - p) for p in frequencies.values()])\n",
    "gini_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set with 2 features and 4 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z, u = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                             n_clusters_per_class=1, n_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Z[:,0],Z[:,1],c=u);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pd.DataFrame(data = Z, columns = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date set from the Visualization Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "x = np.random.uniform(0, 1, n)\n",
    "y = np.random.uniform(0, 1, n)\n",
    "target = norm.pdf((x - 0.75) / 0.1) + norm.pdf((y - 0.75) / 0.1) \\\n",
    "        + norm.pdf((x - 0.25) / 0.1) + norm.pdf((y - 0.25) / 0.1) \\\n",
    "        + np.array(np.round(np.random.normal(-0.1,0.1, n), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = plt.hist(target,bins=20)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    for i in range(len(a)):\n",
    "        if x <= a[i]:\n",
    "            return i\n",
    "        else:\n",
    "            continue   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([f(x) for x in target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame({'x' : x, 'y' : y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Features from Bagging notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_feats = np.array(['fcf_yield', 'oiadpq', 'rd_saleq', 'market_cap', 'oancfy_q',\n",
    "       'oeps12', 'ibadj12', 'book_value_yield', 'oepf12', 'quick_ratioq',\n",
    "       'short_debtq', 'cf_yield', 'sic_6798', 'ibcy', 'xidoy', 'chechy',\n",
    "       'inv_turnq', 'ocf_lctq', 'dpcq', 'cfmq', 'oancfy', 'roeq',\n",
    "       'cfo-per-share', 'txpq', 'opmbdq', 'psq', 'dltisy', 'dltry',\n",
    "       'yearly_sales', 'xsgay', 'lagppent4', 'fcf_ocfq', 'cash_ratioq',\n",
    "       'de_ratioq', 'sale_equityq', 'evmq', 'opepsq', 'dvy', 'actq',\n",
    "       'capxq', 'ceq4', 'fcf_csfhdq', 'sale_invcapq', 'apq', 'dlttq',\n",
    "       'rect_actq', 'capeiq', 'nopiq', 'capxy', 'npmq', 'invt_actq',\n",
    "       'oibdpy', 'accrualq', 'int_totdebtq', 'txtq', 'gpmq',\n",
    "       'aftret_invcapxq', 'dpq'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(optim_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 0.5\n",
    "features = np.random.choice(optim_feats,int(0.5 * len(optim_feats)),replace=False)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = X\n",
    "labels = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 0.5\n",
    "features = np.random.choice(data_set.columns,int(0.5 * len(data_set.columns)),replace=False)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 2\n",
    "x = data_set[2].iloc[234]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_idxs = data_set.index[data_set[f] < x].tolist()\n",
    "R_idxs = data_set.index[data_set[f] >= x].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " L_labels = labels[L_idxs]\n",
    "R_labels = labels[R_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(labels):\n",
    "\n",
    "            C = Counter(labels)\n",
    "            total = len(labels)\n",
    "            frequencies = { k:v/total for (k,v) in C.items()}\n",
    "            gini_index = np.sum([p*(1-p) for p in frequencies.values()])\n",
    "            return gini_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gini_index(L_labels))\n",
    "print(gini_index(R_labels))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_index_of_split = (len(L_labels)*gini_index(L_labels) + len(R_labels)*gini_index(R_labels))/len(data_set)\n",
    "print(gini_index_of_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The RandomForests is an ensemble of Trees. Each Tree is built up of Nodes.\n",
    "\n",
    "### Node Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "        def __init__(self,data:pd.DataFrame = None,labels=None,min_samples_leaf = 1,max_features=0.5):\n",
    "            self.data = data\n",
    "            self.labels = labels\n",
    "            self.left = None\n",
    "            self.right = None\n",
    "            self.split = None\n",
    "            self.max_features = max_features\n",
    "            self.min_samples_leaf = min_samples_leaf\n",
    "            if len(self.data) < 2 * self.min_samples_leaf:\n",
    "                self.isLeaf = True\n",
    "            else: self.isLeaf = False\n",
    "            \n",
    "        def gini_index(self,labels):\n",
    "\n",
    "            C = Counter(labels)\n",
    "            total = len(labels)\n",
    "            frequencies = { k:v/total for (k,v) in C.items()}\n",
    "            gini_index = np.sum([p*(1-p) for p in frequencies.values()])\n",
    "            return gini_index\n",
    "        \n",
    "        def find_best_split(self):\n",
    "            \n",
    "            if self.data.empty:\n",
    "                return\n",
    "            \n",
    "            if len(self.data) < 2*self.min_samples_leaf:\n",
    "                self.isLeaf = True\n",
    "                return\n",
    "\n",
    "        \n",
    "            data_set = self.data.reset_index(drop=True)\n",
    "            labels = self.labels\n",
    "            \n",
    "            \n",
    "            if self.max_features * len(data_set.columns) <= 1:\n",
    "                n=1\n",
    "            else:\n",
    "                n = np.random.choice(range(1,int(self.max_features * len(data_set.columns))+1),1)\n",
    " \n",
    "            random_features = np.random.choice(data_set.columns,n,replace=False)\n",
    "\n",
    "            best_split_gini = np.inf\n",
    "        \n",
    "            best_feature = None\n",
    "            best_value = None\n",
    "        \n",
    "            for f in random_features:\n",
    "           \n",
    "                for x in data_set[f]:\n",
    "                \n",
    "                \n",
    "                    L_idxs = data_set.index[data_set[f] < x].tolist()\n",
    "                    R_idxs = data_set.index[data_set[f] >= x].tolist()\n",
    "\n",
    "\n",
    "                    L_labels = labels[L_idxs]\n",
    "                    R_labels = labels[R_idxs]\n",
    "                    \n",
    "                    if (len(L_labels) < self.min_samples_leaf) or (len(R_labels) < self.min_samples_leaf):\n",
    "                        continue\n",
    "                        \n",
    "                    else:\n",
    "\n",
    "                        gi_L = self.gini_index(L_labels)\n",
    "                        gi_R = self.gini_index(R_labels)\n",
    "\n",
    "                        gini_index_of_split = len(L_idxs) * gi_L + len(R_idxs) * gi_R\n",
    "               \n",
    "                        if gini_index_of_split < best_split_gini:\n",
    "                            best_split_gini = gini_index_of_split\n",
    "                        \n",
    "                            self.left = Node(data=data_set.iloc[L_idxs].reset_index(drop=True),\n",
    "                                             labels = L_labels,min_samples_leaf = self.min_samples_leaf)\n",
    "                \n",
    "                            if (gi_L == 0) or (len(L_labels) < 2 * self.min_samples_leaf):\n",
    "                                    self.left.isLeaf = True\n",
    "\n",
    "                \n",
    "\n",
    "                            self.right = Node(data = data_set.iloc[R_idxs].reset_index(drop=True),\n",
    "                                              labels = R_labels,min_samples_leaf = self.min_samples_leaf)\n",
    "                    \n",
    "                            if (gi_R == 0) or (len(R_labels) < 2 * self.min_samples_leaf):\n",
    "                                       self.right.isLeaf = True\n",
    "\n",
    "                                \n",
    "                            best_feature = f\n",
    "                            best_value = x\n",
    "                        \n",
    "                            self.split = (best_feature,best_value)\n",
    "                                \n",
    "                        else: continue\n",
    "  \n",
    "                return\n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree():\n",
    "    \n",
    "    def __init__(self,root:Node,max_depth = np.inf,min_samples_leaf=1):\n",
    "        self.root = root\n",
    "        self.levels = [[self.root]]\n",
    "        self.max_depth = max_depth\n",
    "        self.splits = []\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.root.min_samples_leaf = self.min_samples_leaf\n",
    "        \n",
    "        self.build_tree()\n",
    "        \n",
    "        \n",
    "    def build_tree(self):\n",
    "        \n",
    "                while np.any([((n != None) and (not n.isLeaf)) for n in self.levels[-1]]) and (len(self.levels) < self.max_depth):\n",
    "                    \n",
    "                    level = []\n",
    "                    \n",
    "                    for node in [n for n in self.levels[-1] if ((n != None) and (not n.isLeaf))]:\n",
    "\n",
    "                        if (node != None) and (not node.isLeaf):\n",
    "\n",
    "                            node.find_best_split()\n",
    "                            level.append(node.left)\n",
    "                            level.append(node.right)\n",
    "                            self.splits.append(node.split)\n",
    "                        \n",
    "                        else: continue\n",
    "                            \n",
    "                    if (len(level)==0):\n",
    "                            return\n",
    "                    else:\n",
    "                            self.levels.append(level) \n",
    "\n",
    "        \n",
    "    def predict(self,x):\n",
    "                      \n",
    "        idx = 0\n",
    "        depth = len(self.levels)\n",
    "        \n",
    "        val = Counter(self.root.labels).most_common()[0][0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(depth):\n",
    "\n",
    "                node = self.levels[i][idx]\n",
    "\n",
    "                if (node.split != None):\n",
    "                \n",
    "                    s = node.split\n",
    "                    \n",
    "  \n",
    "                    if (x[s[0]] < s[1]):\n",
    "#                         if node.left in self.nodes[i+1]:\n",
    "                            idx = self.levels[i+1].index(node.left)\n",
    "                            val = Counter(node.left.labels).most_common()[0][0]\n",
    "                    \n",
    "                    else:\n",
    "#                         if node.right in self.nodes[i+1]:\n",
    "                                idx = self.levels[i+1].index(node.right)                         \n",
    "                                val = Counter(node.right.labels).most_common()[0][0]  \n",
    "                            \n",
    "                else: return val\n",
    "                \n",
    "        return val\n",
    "\n",
    "\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Tree to the make_classification data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Node(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.find_best_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.left.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(root.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(root.labels).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(root.labels).most_common()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Tree(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tree.levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tree.levels[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.levels[8][9].isLeaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.levels[8][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X.iloc[30].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifier():\n",
    "    \n",
    "    def __init__(self,n_estimators=10,max_features=1.0,min_samples_leaf=1,bootstrap=False,max_depth = np.inf,\n",
    "                 random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_depth = max_depth\n",
    "        self.bootstrap = bootstrap\n",
    "        if random_state is not None:\n",
    "            np.random.seed(random_state)\n",
    "        self.trees = []  \n",
    "        \n",
    "    def fit(self,data,labels):\n",
    "        \n",
    "        N = len(labels)\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            if self.bootstrap:\n",
    "                idxs = np.random.choice(range(N),N)\n",
    "                data_set = data.iloc[idxs]\n",
    "                label_set = labels[idxs]\n",
    "            else:\n",
    "                data_set = data\n",
    "                label_set = labels\n",
    "                \n",
    "            root = Node(data_set,label_set)\n",
    "            root.max_features = self.max_features\n",
    "            t = Tree(root,self.max_depth,self.min_samples_leaf)\n",
    "            \n",
    "            self.trees.append(t)\n",
    "            \n",
    "    def predict(self,data_points):\n",
    "            \n",
    "            if len(self.trees) == 0:\n",
    "                print('Classifier needs to be fitted')\n",
    "                return\n",
    "            \n",
    "            if type(data_points) == pd.DataFrame:\n",
    "                data_points = data_points.values\n",
    "            \n",
    "            preds = []\n",
    "            for x in data_points:\n",
    "\n",
    "                x_preds = []\n",
    "                for t in self.trees:\n",
    "                    x_preds.append(t.predict(x))\n",
    "                    \n",
    "                preds.append(Counter(x_preds).most_common()[0][0])\n",
    "                \n",
    "            return preds\n",
    "                \n",
    "                \n",
    "        \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier applied to the 2-dim make_classification data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=15,max_features=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.fit(Z,u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf_clf.predict(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(Z.values,u,rf_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(u,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(u[u == pred])/len(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100,bootstrap=True,max_features=0.5,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.fit(Z,u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rf_clf.predict(Z.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(u,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(Z.values,u,rf_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=40,bootstrap=True,max_depth=4,max_features=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(data,labels,clf):\n",
    "    plot_step = 0.02\n",
    "    x_min, x_max = data[:,0].min() -1, data[:,0].max() + 1\n",
    "    y_min,y_max = data[:,1].min() -1 , data[:,1].max() + 1\n",
    "\n",
    "    xx,yy = np.meshgrid(np.arange(x_min,x_max,plot_step),\n",
    "                   np.arange(y_min,y_max,plot_step))\n",
    "    Z = np.array(clf.predict(np.c_[xx.ravel(),yy.ravel()]))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx,yy,Z,cmap='cool')\n",
    "\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Decision Boundary')\n",
    "\n",
    "    plt.scatter(data[:,0],data[:,1],c=labels,cmap='hot',s=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=10,bootstrap=True,max_depth=4,max_features=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
